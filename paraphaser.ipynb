{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: '[WinError 127] No se encontr√≥ el proceso especificado'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd330f7ea6d540ee98208dc60a9b6488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e1f776c4ba4d55a66d61b03768e212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37121a8a8d4b4176adea9c8ec7fd2501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af85cebe52a451a9cefad8eb0b3f38d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e61f4f37ac94e5ea0ba9c99756f08e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec836561c048477d8f75ebee26f7fe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb9721d0a44982b8c5196022a561d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa49507e79164b99ba278b828cd7e42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dad74db58c42da9d0b551532a1e125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f6e7fe3a934f21ac126d7c71f4a891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18845685  0.17425628  0.0544777   0.29051754  0.16766417 -0.04720685\n",
      "   0.6455801   0.15980878  0.22689246 -0.03089047  0.25588357 -0.05258776\n",
      "  -0.22610131 -0.05710633  0.1304262   0.12495347  0.31749627  0.19444403\n",
      "  -0.5863256  -0.01258601  0.60990924  0.16432746  0.03331131 -0.27383074\n",
      "  -0.2897575  -0.21119693 -0.022614   -0.17035925  0.16158997  0.06082733\n",
      "  -0.24162413  0.18579207  0.42740956  0.19295181 -0.07234461  0.16611095\n",
      "   0.10442816  0.20477231  0.21116719  0.19974002 -0.09408271 -0.17383681\n",
      "   0.06427334  0.28025493 -0.29530576  0.06209534  0.1042768  -0.02364409\n",
      "   0.1291315  -0.12617472 -0.17899013  0.03700576 -0.6125063   0.05029821\n",
      "   0.17730357  0.22494112  0.17386062 -0.0384028  -0.21286823  0.2584924\n",
      "  -0.12101622  0.30971512 -0.41966364  0.00907673  0.14188918 -0.30556944\n",
      "   0.17621139 -0.07087352 -0.6203313   0.6770833   0.01723728  0.18405105\n",
      "  -0.16785777  0.20452647 -0.14770266 -0.0617534   0.63017416  0.11120185\n",
      "   0.05153062  0.15927406 -0.05370887  0.05350972  0.14135517  0.11239239\n",
      "  -0.484118   -0.16993634 -0.053218    0.2765033   0.11777699 -0.34912533\n",
      "  -0.5137555  -0.32844058  0.54240435 -0.05326685  0.22918312 -0.01275999\n",
      "   0.10331804 -0.3362779   0.24765     0.8155244  -0.08930915  0.24757907\n",
      "  -0.12043508  0.01898997  0.32457083 -0.26162407 -0.1971478   0.01440946\n",
      "  -0.03558923 -0.3274298  -0.0482988   0.18030533  0.02312139 -0.14245252\n",
      "  -0.19523919 -0.55491185  0.04146002 -0.08038603 -0.12909903  0.34541205\n",
      "   0.04179794 -0.17788379  0.3445855   0.10763658  0.00641339 -0.8081874\n",
      "   0.18311796 -0.06116304  0.10278976 -0.35960698 -0.12100685 -0.3190547\n",
      "   0.14434473  0.19774674 -0.04758288 -0.13626705  0.2791588   0.1076613\n",
      "  -0.03404955  0.06557187  0.03390295  0.47428322  0.03201617  0.43823138\n",
      "  -0.18881218  0.39110157 -0.2936495  -0.09019408 -0.08186898  0.15285066\n",
      "   0.11806722 -0.29786894  0.18289217 -0.23518276 -0.0433843  -0.08308791\n",
      "  -0.01447868  0.08936629  0.11753732 -0.06312165 -0.13069409  0.16051385\n",
      "  -0.07993042  0.04523456 -0.1163743  -0.1960626   0.03943997 -0.34911755\n",
      "  -0.01147578  0.2608548   0.31661996 -0.08063613 -0.18066724  0.02020079\n",
      "  -0.08835119 -0.01678042 -0.3813458   0.15447453 -0.0322848   0.01385779\n",
      "   0.3147259  -0.29187754 -0.11789715 -0.02333087 -0.22907747  0.24850795\n",
      "  -0.08262329  0.17519854  0.0705316   0.1789045  -0.19748053  0.11594931\n",
      "   0.22957742  0.08844833 -0.34138536 -0.00305381  0.44035402  0.20765059\n",
      "  -0.23839916  0.14549926 -0.32511124 -0.04974937  0.08412294 -0.26103267\n",
      "   0.4220678  -0.27341738  0.22958662 -0.18960802 -0.17343752 -0.046361\n",
      "   0.125531    0.47853255 -0.55295616  0.21560617  0.06972316  0.07278682\n",
      "  -0.23890148  0.19889072 -0.42354283 -0.16452742 -0.22758159 -0.04920293\n",
      "   0.23738706 -0.45531532 -0.06247048  0.5811023  -0.08885682 -0.05396942\n",
      "   0.2865531  -0.48124048 -0.06124129 -0.28116295  0.36897913 -0.29531223\n",
      "  -0.7186569  -0.3877445  -0.16324683  0.13904093 -0.02087954 -0.05228796\n",
      "  -0.10613593 -0.05529133 -0.06380241  0.02985426  0.01341961  0.01263416\n",
      "   0.11067455 -0.07000599 -0.01710509  0.10809227 -0.11134939 -0.42874837\n",
      "  -0.3334115   0.14569536 -0.24261555  0.15181316 -0.08179677  0.24336232\n",
      "  -0.3774545   0.08149547  0.0922083  -0.27653462  0.04063617  0.20002258\n",
      "  -0.04784405 -0.40510845  0.18088542  0.08081252  0.02778461  0.1497763\n",
      "  -0.45252842 -0.06112538  0.2271349  -0.13096143 -0.2984912  -0.15302703\n",
      "  -0.2612384  -0.22188602  0.0426763  -0.20062752 -0.02200277 -0.4943691\n",
      "   0.5353337  -0.02982702 -0.01962634  0.05706311  0.17869149  0.31158468\n",
      "   0.36374235  0.21134543 -0.39374954  0.17488773  0.01140845 -0.10499539\n",
      "  -0.14383797 -0.10661026 -0.43856123  0.04653316 -0.26895496 -0.03211484\n",
      "   0.3126729  -0.2874716  -0.30524972 -0.02647256  0.25250226 -0.1886421\n",
      "   0.21024205  0.07654762 -0.31655508  0.1315559  -0.02851381  0.26622123\n",
      "  -0.43981537  0.33574793 -0.02058741 -0.22813629 -0.1840423   0.15129341\n",
      "  -0.20930657 -0.45565388  0.09736739 -0.17393908 -0.12940069 -0.11562871\n",
      "   0.27910307 -0.15251717  0.16353612 -0.18450578 -0.00569263 -0.3015109\n",
      "  -0.10034242  0.33604607 -0.01101659  0.01471754 -0.07628001  0.78714764\n",
      "  -0.2812058  -0.23819901  0.10064666  0.5990075   0.5006779   0.15818895\n",
      "  -0.29037482  0.06542071 -0.14885983  0.06843913 -0.03958032  0.14649324\n",
      "  -0.14633437  0.17913032  0.28052396  0.36253002 -0.31337675 -0.040918\n",
      "  -0.07653178  0.15323563  0.19257905 -0.37365267  0.0954167  -0.28398445\n",
      "  -0.0014842  -0.04926267  0.44722316  0.6577469   0.1652385   0.05867762\n",
      "  -0.40437835 -0.07801346 -0.25537837 -0.36102334 -0.09678142 -0.14205837\n",
      "   0.1474618   0.09517758  0.05682943 -0.17478296  0.26147905  0.14114742\n",
      "   0.12460987  0.08857516  0.18453883  0.27090254  0.34769484  0.08729649]\n",
      " [ 0.3470767   0.17975076  0.1128896  -0.22380015 -0.02937532  0.00868676\n",
      "   0.56885684 -0.17423849  0.15573621  0.05918523  0.04771052  0.11906709\n",
      "   0.0696125  -0.39164922 -0.11649483  0.39683264 -0.16703571  0.42248797\n",
      "  -0.6075646  -0.23209141  0.06476656  0.16615877 -0.23384604 -0.11623371\n",
      "   0.09024551  0.33958393 -0.16615482 -0.29775572 -0.01450222 -0.31055215\n",
      "  -0.02961067  0.44532546  0.44516343 -0.01631242 -0.1281121   0.29556146\n",
      "  -0.44812799  0.38878638  0.16511391  0.12342677 -0.32385525 -0.08443229\n",
      "   0.17806539  0.05183267  0.31275335  0.06461042 -0.34610438 -0.01012807\n",
      "  -0.07875677  0.3103399  -0.10869171  0.07183921 -0.48495156  0.5769389\n",
      "   0.133601    0.02629808 -0.2509974   0.371164   -0.10699213 -0.17746434\n",
      "  -0.09543949  0.18270278 -0.5296058   0.2284132  -0.02978992 -0.13325101\n",
      "   0.3540957  -0.00828841 -0.24981046  0.53161836 -0.17178173  0.0950513\n",
      "   0.27921182 -0.36492926 -0.15713832  0.28872305  0.20304196  0.05974215\n",
      "   0.13127668  0.05664811 -0.06217083  0.2146628   0.11609137 -0.3990603\n",
      "   0.11946701 -0.248939   -0.13256805  0.4465488   0.31257257 -0.39313343\n",
      "  -0.17129155 -0.5401934   0.7123146   0.08043348  0.17059122 -0.06945728\n",
      "  -0.18228105 -0.3724778   0.5619806   0.36433622 -0.08759423  0.545848\n",
      "  -0.03697032 -0.05890971 -0.2608491  -0.26232585 -0.07935371  0.3217477\n",
      "   0.14701352 -0.18558013 -0.3206956   0.23243818  0.30205438 -0.08602189\n",
      "   0.0082018  -0.15061203  0.27068546 -0.331727    0.0081469   0.7361279\n",
      "  -0.01074328  0.0952621   0.03116512  0.16779839 -0.09472448 -0.32779142\n",
      "   0.1581759  -0.11084626 -0.07533922 -0.28564075  0.08807816  0.12668453\n",
      "  -0.05417131  0.13834664 -0.17383273 -0.17961383  0.1591357  -0.13249208\n",
      "  -0.02498729 -0.02863712  0.22149916  0.41240948 -0.09995217  0.39165792\n",
      "  -0.03023232  0.19657326 -0.508957   -0.13262288 -0.08178659  0.31298634\n",
      "  -0.24409056 -0.15581368 -0.27632207 -0.26031104  0.02606729  0.15951855\n",
      "  -0.02367792 -0.05711333 -0.21294382  0.08174991 -0.08173851  0.19129154\n",
      "  -0.29870144  0.19334713  0.26285186  0.07807036  0.08929729  0.18175307\n",
      "  -0.24137019 -0.00128376  0.5129107  -0.24898441 -0.28275123 -0.3293907\n",
      "  -0.27734903  0.30010805 -0.1064432   0.1497766   0.2015277   0.14604986\n",
      "   0.08155496 -0.15151139 -0.36765543  0.2851122  -0.20097066  0.04080789\n",
      "  -0.45554778  0.08342902 -0.07359825  0.2958781   0.05567539 -0.3490295\n",
      "   0.09901802 -0.01793148 -0.25333777 -0.05929403  0.21367738  0.21086922\n",
      "  -0.5560664   0.12414748  0.04702964  0.06113522 -0.00192881 -0.47759977\n",
      "   0.18244515  0.07414548 -0.39272016 -0.17483972 -0.06648699  0.28929213\n",
      "  -0.00717114  0.13004671  0.34543553  0.00546765  0.27574164  0.0719846\n",
      "  -0.00558628 -0.22266825  0.02625502 -0.39822865  0.16638331 -0.38634902\n",
      "   0.36284992 -0.21355097 -0.21243003  0.6678387  -0.19671024  0.32093588\n",
      "  -0.17523853 -0.3111673  -0.26940387 -0.0679431   0.05132957 -0.43308273\n",
      "  -0.06844494 -0.25163183 -0.23884143  0.04973091 -0.18011369  0.02875857\n",
      "   0.10885776  0.39926645  0.010267    0.04654554  0.04425427  0.18722226\n",
      "  -0.06429295  0.05355756 -0.15590551 -0.10054206  0.29329866 -0.04835651\n",
      "   0.02299047  0.3100094  -0.06247517  0.02948101 -0.32953915  0.5130008\n",
      "  -0.3465161  -0.19149867  0.26188543 -0.02514708 -0.10117871  0.6904425\n",
      "   0.28683904 -0.42476058 -0.34004554 -0.02383406  0.03670328 -0.21457794\n",
      "  -0.31357542  0.06676701 -0.06548506 -0.14639921  0.18192518 -0.15907094\n",
      "  -0.49846768 -0.21165803  0.11630959 -0.26992592  0.16266456 -0.643194\n",
      "   0.3200359   0.08476806 -0.00833988  0.13469388  0.20395763 -0.0488351\n",
      "   0.22934565  0.12962976 -0.28847164 -0.01838061  0.1663569  -0.25723925\n",
      "  -0.18950157  0.2668058  -0.53406245  0.03297418 -0.16005285 -0.34828988\n",
      "  -0.1348066  -0.07903029 -0.4003721   0.23914893 -0.18939856 -0.22996119\n",
      "  -0.26500937  0.30550027 -0.21577822  0.12839952  0.22074068  0.02465521\n",
      "  -0.37391227  0.34780627 -0.1608559  -0.03523717  0.1970875   0.05138618\n",
      "  -0.24489093  0.04642859  0.10596126 -0.03903052 -0.39346647  0.35392648\n",
      "   0.26167685 -0.20305446  0.06714205 -0.2900629   0.21563104 -0.11339251\n",
      "  -0.11325756  0.5838539  -0.3625657   0.09554897 -0.18850958  0.5221066\n",
      "   0.01045498  0.08855109 -0.19684854  0.52225983  0.58784324  0.0795956\n",
      "  -0.18018723 -0.02912614 -0.11641083  0.33799314  0.13571595  0.0102751\n",
      "  -0.408446   -0.1747562   0.12402969  0.12424032 -0.2174561   0.26906413\n",
      "  -0.10524548 -0.06161279  0.4625972  -0.15411507  0.23713921  0.18526651\n",
      "   0.09552389 -0.40052673  0.03717394  0.28664213 -0.29808196 -0.2248323\n",
      "  -0.13735838 -0.21555264 -0.02228167 -0.22343762 -0.21233962  0.11212627\n",
      "   0.06114588 -0.27714586  0.2833104  -0.2533836   0.61102915  0.34967223\n",
      "   0.27692598  0.1729504  -0.18559727  0.3126668   0.02952215 -0.2769554 ]]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.1885,  0.1743,  0.0545,  0.2905,  0.1677, -0.0472,  0.6456,  0.1598,\n",
      "          0.2269, -0.0309,  0.2559, -0.0526, -0.2261, -0.0571,  0.1304,  0.1250,\n",
      "          0.3175,  0.1944, -0.5863, -0.0126,  0.6099,  0.1643,  0.0333, -0.2738,\n",
      "         -0.2898, -0.2112, -0.0226, -0.1704,  0.1616,  0.0608, -0.2416,  0.1858,\n",
      "          0.4274,  0.1930, -0.0723,  0.1661,  0.1044,  0.2048,  0.2112,  0.1997,\n",
      "         -0.0941, -0.1738,  0.0643,  0.2803, -0.2953,  0.0621,  0.1043, -0.0236,\n",
      "          0.1291, -0.1262, -0.1790,  0.0370, -0.6125,  0.0503,  0.1773,  0.2249,\n",
      "          0.1739, -0.0384, -0.2129,  0.2585, -0.1210,  0.3097, -0.4197,  0.0091,\n",
      "          0.1419, -0.3056,  0.1762, -0.0709, -0.6203,  0.6771,  0.0172,  0.1841,\n",
      "         -0.1679,  0.2045, -0.1477, -0.0618,  0.6302,  0.1112,  0.0515,  0.1593,\n",
      "         -0.0537,  0.0535,  0.1414,  0.1124, -0.4841, -0.1699, -0.0532,  0.2765,\n",
      "          0.1178, -0.3491, -0.5138, -0.3284,  0.5424, -0.0533,  0.2292, -0.0128,\n",
      "          0.1033, -0.3363,  0.2476,  0.8155, -0.0893,  0.2476, -0.1204,  0.0190,\n",
      "          0.3246, -0.2616, -0.1971,  0.0144, -0.0356, -0.3274, -0.0483,  0.1803,\n",
      "          0.0231, -0.1425, -0.1952, -0.5549,  0.0415, -0.0804, -0.1291,  0.3454,\n",
      "          0.0418, -0.1779,  0.3446,  0.1076,  0.0064, -0.8082,  0.1831, -0.0612,\n",
      "          0.1028, -0.3596, -0.1210, -0.3191,  0.1443,  0.1977, -0.0476, -0.1363,\n",
      "          0.2792,  0.1077, -0.0340,  0.0656,  0.0339,  0.4743,  0.0320,  0.4382,\n",
      "         -0.1888,  0.3911, -0.2936, -0.0902, -0.0819,  0.1529,  0.1181, -0.2979,\n",
      "          0.1829, -0.2352, -0.0434, -0.0831, -0.0145,  0.0894,  0.1175, -0.0631,\n",
      "         -0.1307,  0.1605, -0.0799,  0.0452, -0.1164, -0.1961,  0.0394, -0.3491,\n",
      "         -0.0115,  0.2609,  0.3166, -0.0806, -0.1807,  0.0202, -0.0884, -0.0168,\n",
      "         -0.3813,  0.1545, -0.0323,  0.0139,  0.3147, -0.2919, -0.1179, -0.0233,\n",
      "         -0.2291,  0.2485, -0.0826,  0.1752,  0.0705,  0.1789, -0.1975,  0.1159,\n",
      "          0.2296,  0.0884, -0.3414, -0.0031,  0.4404,  0.2077, -0.2384,  0.1455,\n",
      "         -0.3251, -0.0497,  0.0841, -0.2610,  0.4221, -0.2734,  0.2296, -0.1896,\n",
      "         -0.1734, -0.0464,  0.1255,  0.4785, -0.5530,  0.2156,  0.0697,  0.0728,\n",
      "         -0.2389,  0.1989, -0.4235, -0.1645, -0.2276, -0.0492,  0.2374, -0.4553,\n",
      "         -0.0625,  0.5811, -0.0889, -0.0540,  0.2866, -0.4812, -0.0612, -0.2812,\n",
      "          0.3690, -0.2953, -0.7187, -0.3877, -0.1632,  0.1390, -0.0209, -0.0523,\n",
      "         -0.1061, -0.0553, -0.0638,  0.0299,  0.0134,  0.0126,  0.1107, -0.0700,\n",
      "         -0.0171,  0.1081, -0.1113, -0.4287, -0.3334,  0.1457, -0.2426,  0.1518,\n",
      "         -0.0818,  0.2434, -0.3775,  0.0815,  0.0922, -0.2765,  0.0406,  0.2000,\n",
      "         -0.0478, -0.4051,  0.1809,  0.0808,  0.0278,  0.1498, -0.4525, -0.0611,\n",
      "          0.2271, -0.1310, -0.2985, -0.1530, -0.2612, -0.2219,  0.0427, -0.2006,\n",
      "         -0.0220, -0.4944,  0.5353, -0.0298, -0.0196,  0.0571,  0.1787,  0.3116,\n",
      "          0.3637,  0.2113, -0.3937,  0.1749,  0.0114, -0.1050, -0.1438, -0.1066,\n",
      "         -0.4386,  0.0465, -0.2690, -0.0321,  0.3127, -0.2875, -0.3052, -0.0265,\n",
      "          0.2525, -0.1886,  0.2102,  0.0765, -0.3166,  0.1316, -0.0285,  0.2662,\n",
      "         -0.4398,  0.3357, -0.0206, -0.2281, -0.1840,  0.1513, -0.2093, -0.4557,\n",
      "          0.0974, -0.1739, -0.1294, -0.1156,  0.2791, -0.1525,  0.1635, -0.1845,\n",
      "         -0.0057, -0.3015, -0.1003,  0.3360, -0.0110,  0.0147, -0.0763,  0.7871,\n",
      "         -0.2812, -0.2382,  0.1006,  0.5990,  0.5007,  0.1582, -0.2904,  0.0654,\n",
      "         -0.1489,  0.0684, -0.0396,  0.1465, -0.1463,  0.1791,  0.2805,  0.3625,\n",
      "         -0.3134, -0.0409, -0.0765,  0.1532,  0.1926, -0.3737,  0.0954, -0.2840,\n",
      "         -0.0015, -0.0493,  0.4472,  0.6577,  0.1652,  0.0587, -0.4044, -0.0780,\n",
      "         -0.2554, -0.3610, -0.0968, -0.1421,  0.1475,  0.0952,  0.0568, -0.1748,\n",
      "          0.2615,  0.1411,  0.1246,  0.0886,  0.1845,  0.2709,  0.3477,  0.0873],\n",
      "        [ 0.3471,  0.1798,  0.1129, -0.2238, -0.0294,  0.0087,  0.5689, -0.1742,\n",
      "          0.1557,  0.0592,  0.0477,  0.1191,  0.0696, -0.3916, -0.1165,  0.3968,\n",
      "         -0.1670,  0.4225, -0.6076, -0.2321,  0.0648,  0.1662, -0.2338, -0.1162,\n",
      "          0.0902,  0.3396, -0.1662, -0.2978, -0.0145, -0.3106, -0.0296,  0.4453,\n",
      "          0.4452, -0.0163, -0.1281,  0.2956, -0.4481,  0.3888,  0.1651,  0.1234,\n",
      "         -0.3239, -0.0844,  0.1781,  0.0518,  0.3128,  0.0646, -0.3461, -0.0101,\n",
      "         -0.0788,  0.3103, -0.1087,  0.0718, -0.4850,  0.5769,  0.1336,  0.0263,\n",
      "         -0.2510,  0.3712, -0.1070, -0.1775, -0.0954,  0.1827, -0.5296,  0.2284,\n",
      "         -0.0298, -0.1333,  0.3541, -0.0083, -0.2498,  0.5316, -0.1718,  0.0951,\n",
      "          0.2792, -0.3649, -0.1571,  0.2887,  0.2030,  0.0597,  0.1313,  0.0566,\n",
      "         -0.0622,  0.2147,  0.1161, -0.3991,  0.1195, -0.2489, -0.1326,  0.4465,\n",
      "          0.3126, -0.3931, -0.1713, -0.5402,  0.7123,  0.0804,  0.1706, -0.0695,\n",
      "         -0.1823, -0.3725,  0.5620,  0.3643, -0.0876,  0.5458, -0.0370, -0.0589,\n",
      "         -0.2608, -0.2623, -0.0794,  0.3217,  0.1470, -0.1856, -0.3207,  0.2324,\n",
      "          0.3021, -0.0860,  0.0082, -0.1506,  0.2707, -0.3317,  0.0081,  0.7361,\n",
      "         -0.0107,  0.0953,  0.0312,  0.1678, -0.0947, -0.3278,  0.1582, -0.1108,\n",
      "         -0.0753, -0.2856,  0.0881,  0.1267, -0.0542,  0.1383, -0.1738, -0.1796,\n",
      "          0.1591, -0.1325, -0.0250, -0.0286,  0.2215,  0.4124, -0.1000,  0.3917,\n",
      "         -0.0302,  0.1966, -0.5090, -0.1326, -0.0818,  0.3130, -0.2441, -0.1558,\n",
      "         -0.2763, -0.2603,  0.0261,  0.1595, -0.0237, -0.0571, -0.2129,  0.0817,\n",
      "         -0.0817,  0.1913, -0.2987,  0.1933,  0.2629,  0.0781,  0.0893,  0.1818,\n",
      "         -0.2414, -0.0013,  0.5129, -0.2490, -0.2828, -0.3294, -0.2773,  0.3001,\n",
      "         -0.1064,  0.1498,  0.2015,  0.1460,  0.0816, -0.1515, -0.3677,  0.2851,\n",
      "         -0.2010,  0.0408, -0.4555,  0.0834, -0.0736,  0.2959,  0.0557, -0.3490,\n",
      "          0.0990, -0.0179, -0.2533, -0.0593,  0.2137,  0.2109, -0.5561,  0.1241,\n",
      "          0.0470,  0.0611, -0.0019, -0.4776,  0.1824,  0.0741, -0.3927, -0.1748,\n",
      "         -0.0665,  0.2893, -0.0072,  0.1300,  0.3454,  0.0055,  0.2757,  0.0720,\n",
      "         -0.0056, -0.2227,  0.0263, -0.3982,  0.1664, -0.3863,  0.3628, -0.2136,\n",
      "         -0.2124,  0.6678, -0.1967,  0.3209, -0.1752, -0.3112, -0.2694, -0.0679,\n",
      "          0.0513, -0.4331, -0.0684, -0.2516, -0.2388,  0.0497, -0.1801,  0.0288,\n",
      "          0.1089,  0.3993,  0.0103,  0.0465,  0.0443,  0.1872, -0.0643,  0.0536,\n",
      "         -0.1559, -0.1005,  0.2933, -0.0484,  0.0230,  0.3100, -0.0625,  0.0295,\n",
      "         -0.3295,  0.5130, -0.3465, -0.1915,  0.2619, -0.0251, -0.1012,  0.6904,\n",
      "          0.2868, -0.4248, -0.3400, -0.0238,  0.0367, -0.2146, -0.3136,  0.0668,\n",
      "         -0.0655, -0.1464,  0.1819, -0.1591, -0.4985, -0.2117,  0.1163, -0.2699,\n",
      "          0.1627, -0.6432,  0.3200,  0.0848, -0.0083,  0.1347,  0.2040, -0.0488,\n",
      "          0.2293,  0.1296, -0.2885, -0.0184,  0.1664, -0.2572, -0.1895,  0.2668,\n",
      "         -0.5341,  0.0330, -0.1601, -0.3483, -0.1348, -0.0790, -0.4004,  0.2391,\n",
      "         -0.1894, -0.2300, -0.2650,  0.3055, -0.2158,  0.1284,  0.2207,  0.0247,\n",
      "         -0.3739,  0.3478, -0.1609, -0.0352,  0.1971,  0.0514, -0.2449,  0.0464,\n",
      "          0.1060, -0.0390, -0.3935,  0.3539,  0.2617, -0.2031,  0.0671, -0.2901,\n",
      "          0.2156, -0.1134, -0.1133,  0.5839, -0.3626,  0.0955, -0.1885,  0.5221,\n",
      "          0.0105,  0.0886, -0.1968,  0.5223,  0.5878,  0.0796, -0.1802, -0.0291,\n",
      "         -0.1164,  0.3380,  0.1357,  0.0103, -0.4084, -0.1748,  0.1240,  0.1242,\n",
      "         -0.2175,  0.2691, -0.1052, -0.0616,  0.4626, -0.1541,  0.2371,  0.1853,\n",
      "          0.0955, -0.4005,  0.0372,  0.2866, -0.2981, -0.2248, -0.1374, -0.2156,\n",
      "         -0.0223, -0.2234, -0.2123,  0.1121,  0.0611, -0.2771,  0.2833, -0.2534,\n",
      "          0.6110,  0.3497,  0.2769,  0.1730, -0.1856,  0.3127,  0.0295, -0.2770]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, max pooling.\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
